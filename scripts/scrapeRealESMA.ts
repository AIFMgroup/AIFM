/**
 * Real ESMA Document Scraper Script
 * 
 * HÃ¤mtar faktiska PDF:er frÃ¥n ESMA och extraherar text.
 * Usage: npx tsx scripts/scrapeRealESMA.ts
 */

import { runRealESMAScraper, listESMADocumentRegistry } from '../lib/compliance/scrapers/realEsmaScraper';
import { complianceDocStore } from '../lib/compliance/documentStore';
import { processDocument } from '../lib/compliance/ragPipeline';

async function main() {
  console.log('ğŸ‡ªğŸ‡º Real ESMA Document Scraper');
  console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n');
  
  // Show registry
  const registry = listESMADocumentRegistry();
  console.log(`ğŸ“‹ Document Registry: ${registry.length} documents\n`);
  
  console.log('Categories:');
  const cats: Record<string, number> = {};
  registry.forEach(r => r.categories.forEach(c => cats[c] = (cats[c] || 0) + 1));
  Object.entries(cats).forEach(([k, v]) => console.log(`   ${k}: ${v}`));
  
  console.log('\nTypes:');
  const types: Record<string, number> = {};
  registry.forEach(r => types[r.type] = (types[r.type] || 0) + 1);
  Object.entries(types).forEach(([k, v]) => console.log(`   ${k}: ${v}`));
  
  console.log('\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
  console.log('ğŸš€ Starting scrape...\n');
  
  // Run scraper
  const result = await runRealESMAScraper();
  
  console.log('\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
  console.log('ğŸ“Š SCRAPE RESULTS');
  console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
  console.log(`Documents found:    ${result.documentsFound}`);
  console.log(`Documents new:      ${result.documentsNew}`);
  console.log(`Errors:             ${result.errors.length}`);
  console.log(`Duration:           ${Math.round(result.duration / 1000)}s`);
  
  if (result.errors.length > 0) {
    console.log('\nâš ï¸  Errors:');
    result.errors.forEach(e => console.log(`   - ${e}`));
  }
  
  // Now process documents for RAG
  console.log('\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
  console.log('ğŸ”„ Processing for RAG (chunking + embeddings)...\n');
  
  const docs = await complianceDocStore.listBySource('esma', 100);
  let processed = 0;
  const chunksTotal = 0;
  
  for (const doc of docs) {
    if (doc.fullText && doc.fullText.length > 200) {
      try {
        process.stdout.write(`   ${doc.shortTitle || doc.documentNumber}... `);
        await processDocument(doc);
        processed++;
        console.log('âœ…');
      } catch (error) {
        console.log(`âŒ ${(error as Error).message?.substring(0, 30)}`);
      }
      
      // Rate limit
      await new Promise(resolve => setTimeout(resolve, 500));
    }
  }
  
  console.log('\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
  console.log('âœ… COMPLETED');
  console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
  console.log(`Documents scraped:  ${result.documentsNew}`);
  console.log(`Documents processed: ${processed}`);
  console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n');
}

main().catch(err => {
  console.error('Fatal error:', err);
  process.exit(1);
});




